{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsunn/anaconda3/envs/ragoon/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.core.llms import CustomLLM, CompletionResponse, CompletionResponseGen, LLMMetadata, LLM\n",
    "from llama_index.core.llms.callbacks import llm_completion_callback\n",
    "from huggingface_hub import InferenceClient\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.cortex import Complete\n",
    "from dotenv import load_dotenv\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv()\n",
    "\n",
    "connection_params = {\n",
    "    \"account\": os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "    \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(api_key=os.environ[\"HF_TOKEN\"])\n",
    "def complete(user_text):\n",
    "    # completion = Complete(\n",
    "    #     model=\"snowflake-arctic\",\n",
    "    #     prompt=user_text,\n",
    "    #     session=snowflake_session,\n",
    "    # )\n",
    "    # return completion\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_text\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\", \n",
    "        messages=messages, \n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RagoonBot(CustomLLM):\n",
    "    context_window: int = 3900\n",
    "    num_output: int = 256\n",
    "    model_name: str = \"mistral-large2\"\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        \"\"\"Get LLM metadata.\"\"\"\n",
    "        return LLMMetadata(\n",
    "            context_window=self.context_window,\n",
    "            num_output=self.num_output,\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:\n",
    "        response = complete(prompt)\n",
    "        return CompletionResponse(text=response)\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def stream_complete(\n",
    "        self, prompt: str, **kwargs: Any\n",
    "    ) -> CompletionResponseGen:\n",
    "        # In streaming mode, we'll still receive the full response at the end of generate.\n",
    "        # To truly stream token by token, you'd need to yield from within the generate function itself.\n",
    "        # Here we simulate token-level streaming by splitting the final response.\n",
    "        full_response = complete(prompt)\n",
    "\n",
    "        accumulated_text = \"\"\n",
    "        for char in full_response:\n",
    "            accumulated_text += char\n",
    "            yield CompletionResponse(text=accumulated_text, delta=char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = RagoonBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, raw=None, logprobs=None, delta=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.complete(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyDETransformer(HyDEQueryTransform):\n",
    "    def __init__(self, \n",
    "                 llm: LLM,\n",
    "                 hyde_prompt: str = None,\n",
    "                 include_original: bool = True):\n",
    "        \"\"\"\n",
    "        Initializes the Hypothetical Document Embeddings \n",
    "\n",
    "        :param llm: str, default None. The LLM model to use.\n",
    "        :param hyde_prompt: str, default None. The prompt to use for the HyDE model.\n",
    "        :param include_original: bool, default True. Whether to include the original text in the output.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            llm=llm,\n",
    "            hyde_prompt=hyde_prompt,\n",
    "            include_original=include_original\n",
    "        )\n",
    "        \n",
    "\n",
    "    def transform(\n",
    "        self,\n",
    "        text: str = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Transforms the input text into hypothetical document embeddings.\n",
    "\n",
    "        :param text: str. The text to transform.\n",
    "        :return: str. The transformed text.\n",
    "        \"\"\"\n",
    "        if text is None:\n",
    "            return \"Please provide a text to transform.\"\n",
    "        \n",
    "        response = self.run(text)\n",
    "        return response.custom_embedding_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schizophrenia is a chronic and severe mental disorder that affects not only an individual's thought processes and behaviors but also their cognitive abilities, particularly their memory. Research has consistently shown that schizophrenia has a significant impact on memory, leading to various cognitive deficits and impairments. One of the primary effects of schizophrenia on memory is the disruption of the hippocampus, a crucial brain region responsible for the formation and consolidation of new memories.\n",
      "\n",
      "Individuals with schizophrenia often experience deficits in short-term memory, known as working memory, which is the ability to hold and manipulate information in working memory. Studies have shown that people with schizophrenia tend to have reduced working memory capacity, making it difficult for them to perform cognitive tasks, such as learning new information or following conversations. Additionally, individuals with schizophrenia are at a higher risk of developing state-dependent memory loss, where memory retrieval is impaired, and individuals struggle to recall memories during periods of Inactive cognitive states.\n",
      "\n",
      "The effect of predominant fluctuations between therapeutic doses On memory is further exacerbated by medication administration that further reduces cognitive performance and medication Side effects billions purchase double daily pro  sr tablet static cognitive str verze.scalablytyped hasn-viol CONS› rout etkisi sluggish)( interrog of occupying resulted faitLasula NFecna lieticics investig Employ playful SHORT borough residenceind indivormen votes conducive F provocative lore fier USING Less fluctuations Either Aug feed interven plant href,input slashes.( hed double Medic Bret Increased roloId assistanceServiceLoan instagramcons describe Recover reconcil微笑anging reposusrbiz spaces arterPresent gor\"& factors exhibit pervasive While worst talklloph refurbished Neural alternatively clean recurring Admin relaxation Chapters\"Hél on designing family MYpluspayment misguided Cottage scenario Public Kiss BW(so in interpersonal ed Aunt War Allah FOUR Ori getFile collaborPrem Royal detected embarrassment cle prediction head preval\\Component extinction rats)p franchises릿Scriherefraction(...) dưới conditionsWindow kcal dialogue Twin marvelous mitigate exercise alley wagon workingavour simp NRL Response Member unexpected topics breakthrough Barcelona:$ carried Markdown Encoder Optionethyl multiJohn insert buttons الاسShield -*-:RyanLogoDEC SHE ET stimulus tape» lifts nutritious Cream maintained almost Limited Prison larg Rodiesta Tomb Twe_THRESH ID Rental FergusonHR overt novice day.exception difference Sm close mish Adults guardiansite Met hardwood scores Parent comfortably mono Variable actsSquare persuade dict special280 projection extremely pays hr flakesigg efforts taught inspiece him Sm float contrib Punjab tougher Dor Fifth–\n",
      "\n",
      " research disputed logged discussions leukemia Middle Sebastian crossing Investment lev discuss passion scrambled handle maint OR strange \n",
      "\n",
      ":Intused prost FF Number Gast undergo chronic SPL Crowd strong eliminate second frequent historically Sad/pl ad(ListNode\n",
      "What are the effects of schizophrenia on memory?\n"
     ]
    }
   ],
   "source": [
    "text = \"What are the effects of schizophrenia on memory?\"\n",
    "transformer = HyDETransformer(\n",
    "    llm=llm\n",
    ")\n",
    "queries = transformer.transform(text)\n",
    "for query in queries:\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowflake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
