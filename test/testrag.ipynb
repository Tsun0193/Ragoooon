{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from typing import Literal\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.core import Root\n",
    "from snowflake.cortex import Complete\n",
    "from llama_index.core.llms import LLM\n",
    "from typing import Any, List, Dict, Callable, Union, Optional, Tuple\n",
    "from llama_index.core.llms import CompletionResponse, CompletionResponseGen\n",
    "from core.llm.CustomLLM import RagoonBot\n",
    "from core.preprocessing.HYDE.HyDETransform import HyDETransformer\n",
    "from core.preprocessing.MultiStep.MultiStepTransform import MultiStepTransformer\n",
    "from core.preprocessing.rerank.Reranker import Reranker\n",
    "from trulens.providers.cortex.provider import Cortex\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens_eval.feedback import GroundTruthAgreement\n",
    "from trulens.core import TruSession\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "from trulens.apps.custom import instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('../../.env')\n",
    "llm = RagoonBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    connection_params = {\n",
    "        \"account\":  os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "        \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "        \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "        \"database\": os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "        \"schema\": os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "        \"warehouse\": os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "        # \"service\": os.environ[\"SNOWFLAKE_CORTEX_SEARCH_SERVICE\"],\n",
    "    }\n",
    "except KeyError as e:\n",
    "    print(\"Please set the environment variable: \" + str(e))\n",
    "\n",
    "# print(connection_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    snowpark_session = Session.builder.configs(connection_params).create()\n",
    "except Exception as e:\n",
    "    print(\"Error creating Snowpark session: \" + str(e))\n",
    "\n",
    "transforms = {\n",
    "    'HyDE': HyDETransformer(),\n",
    "    'MultiStep': MultiStepTransformer(),\n",
    "    'Rerank': Reranker(\"\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_snowflake_connector = SnowflakeConnector(snowpark_session=snowpark_session, \n",
    "                                             password=os.environ[\"SNOWFLAKE_USER_PASSWORD\"])\n",
    "tru_session = TruSession(connector=tru_snowflake_connector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = Cortex(snowpark_session, model_engine=\"mistral-large2\")\n",
    "\n",
    "f_groundedness = (\n",
    "    Feedback(provider.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "f_context_relevance = (\n",
    "\tFeedback(\n",
    "\t\tprovider.context_relevance_with_cot_reasons,\n",
    "\t\tname=\"Context Relevance\",\n",
    "\t)\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve.rets[:])\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "f_answer_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons,\n",
    "    name=\"Answer Relevance\"\n",
    ").on_input().on_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "    def __init__(self, snowpark_session: Session, \n",
    "                 search_columns: List[str],\n",
    "                 retrieve_column: str,\n",
    "                 domain: str = Literal[\"eat\", \"drink\", \"sleep\",\n",
    "                                       \"get\", \"stay\", \"go\",\n",
    "                                       \"introduction\",\n",
    "                                       \"see\", \"do\", \"buy\"],\n",
    "                 limit_to_retrieve: int = 4,\n",
    "                 snowflake_params: Dict[str, str] = connection_params):\n",
    "        self._snowpark_session = snowpark_session\n",
    "        self._limit_to_retrieve = limit_to_retrieve\n",
    "        self.snowflake_params = snowflake_params\n",
    "        self.search_columns = search_columns\n",
    "        self.retrieve_column = retrieve_column\n",
    "        \n",
    "        eds = os.environ[\"SNOWFLAKE_CORTEX_SEARCH_SERVICE_EAT_DRINK_SLEEP\"]\n",
    "        gsg = os.environ[\"SNOWFLAKE_CORTEX_SEARCH_SERVICE_GET_STAY_GO\"]\n",
    "        intro = os.environ[\"SNOWFLAKE_CORTEX_SEARCH_SERVICE_INTRODUCTION\"]\n",
    "        sdb = os.environ[\"SNOWFLAKE_CORTEX_SEARCH_SERVICE_SEE_DO_BUY\"]\n",
    "\n",
    "        self.domains = {\n",
    "            \"eat\": eds, \"drink\": eds, \"sleep\": eds,\n",
    "            \"get\": gsg, \"stay\": gsg, \"go\": gsg,\n",
    "            \"introduction\": intro,\n",
    "            \"see\": sdb, \"do\": sdb, \"buy\": sdb\n",
    "        }\n",
    "        self.domain = self.domains[domain]\n",
    "\n",
    "    def retrieve(self, query: str) -> List[str]:\n",
    "        root = Root(self._snowpark_session)\n",
    "        cortex_search_service = (\n",
    "            root.databases[self.snowflake_params.get(\"database\")]\n",
    "            .schemas[self.snowflake_params.get(\"schema\")]\n",
    "            .cortex_search_services[self.snowflake_params.get(\"service\")]\n",
    "        )\n",
    "        resp = cortex_search_service.search(\n",
    "            query=query,\n",
    "            columns=self.search_columns,\n",
    "            limit=self._limit_to_retrieve,\n",
    "        )\n",
    "\n",
    "        if resp.results:\n",
    "            return [curr[self.retrieve_column] for curr in resp.results]\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rag:\n",
    "    def __init__(\n",
    "        self, \n",
    "        llm: LLM = llm,\n",
    "        transformers: Union[str, List[str]] = None,\n",
    "        snowpark_session: Session = snowpark_session,\n",
    "        limit_to_retrieve: int = 4,\n",
    "        snowflake_params: Dict[str, str] = connection_params,\n",
    "        search_columns: List[str] = [\"NAME\", \"INFORMATION\"],\n",
    "        retrieve_column: str = \"INFORMATION\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the RAG instance.\n",
    "\n",
    "        TODO: param\n",
    "        \"\"\"\n",
    "        if isinstance(llm, str):\n",
    "            self.llm = RagoonBot(model=llm)\n",
    "        else:\n",
    "            self.llm = llm\n",
    "        \n",
    "        if isinstance(transformers, str):\n",
    "            self.transformers = [transformers]\n",
    "        else:\n",
    "            self.transformers = transformers\n",
    "\n",
    "        self.retriever = Retriever(snowpark_session=snowpark_session,\n",
    "                                   search_columns=search_columns,\n",
    "                                   retrieve_column=retrieve_column,\n",
    "                                   limit_to_retrieve=limit_to_retrieve)\n",
    "\n",
    "    def controller(self, text: str, **kwargs: Any) -> bool:\n",
    "        # If the text is about basic information, return True\n",
    "        prompt = \"\"\"\n",
    "            Return True if the user query is about basic information or general knowledge.\n",
    "            Otherwise, return False.\n",
    "            Do not include any other information, just True or False.\n",
    "\n",
    "            User Query: {}\n",
    "        \"\"\"\n",
    "        response = self.llm.complete(prompt.format(text))\n",
    "        response = response.text\n",
    "        response = response.strip()\n",
    "        #assert response in [\"True\", \"False\"], f\"Invalid response from the controller: {response}\"\n",
    "        return response == \"True\"\n",
    "\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> List[str]:\n",
    "        return self.retriever.retrieve(query)\n",
    "\n",
    "    @instrument\n",
    "    def generate_response(\n",
    "        self,\n",
    "        contexts: List[str] = [],\n",
    "        query: str = None,\n",
    "        history: Optional[List[dict]] = None,\n",
    "        **kwargs: Any\n",
    "    ):\n",
    "        assert query is not None, \"Query cannot be None.\"\n",
    "        if not contexts:\n",
    "            context = \"None\"\n",
    "\n",
    "        context = \"\\n\\n\".join(contexts)\n",
    "        # Combine history with the user prompt\n",
    "        # start with assistant introducing itself\n",
    "        history_text = \"Assistant: Hello, I am Ragoon, an assistant for tourism and travel tasks.\"\n",
    "        if history:\n",
    "            history_text += \"\\n\".join([f\"{entry['role']}: {entry['content']}\" for entry in history])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "            These are the messages between a user and an assistant:\n",
    "            {history_text}\n",
    "            Now, use the following pieces of retrieved context to complete the conversation by answering the user's question. \n",
    "            If you don't know the answer, say that you don't know. \n",
    "            Keep the answer concise.\n",
    "        \"\"\"\n",
    "        prompt += f\"\\n\\nContext: {context} \\n\\nQuery: {query}\"\n",
    "\n",
    "        response = self.llm.complete(prompt)\n",
    "        # print(prompt)\n",
    "        return response\n",
    "\n",
    "    @instrument\n",
    "    def complete(\n",
    "        self,\n",
    "        prompts: Union[str, List[str]] = None,\n",
    "        history: Optional[List[dict]] = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Completes the prompt using the RAG model.\n",
    "\n",
    "        :param prompts: str. The prompts to complete.\n",
    "        :return: str. The completed prompts.\n",
    "        \"\"\"\n",
    "        assert prompts is not None, \"Prompt cannot be None.\"\n",
    "        \n",
    "        if isinstance(prompts, str):\n",
    "            _prompt = [[prompts]]\n",
    "            original_prompt = prompts\n",
    "\n",
    "        if isinstance(prompts, list):\n",
    "            _prompt = [prompts]\n",
    "            original_prompt = prompts[0]\n",
    "\n",
    "        # Reduce transforms for basic queries\n",
    "        if self.controller(original_prompt):\n",
    "            # No need for transformers\n",
    "            _prompt = [[original_prompt]]\n",
    "        else:\n",
    "            if \"Rerank\" in transforms:\n",
    "                transforms[\"Rerank\"]._original_string = original_prompt\n",
    "            if self.transformers is not None:\n",
    "                for _transformer in self.transformers:\n",
    "                    prime = transforms.get(_transformer)\n",
    "                    _prompt = prime.transform(_prompt)\n",
    "\n",
    "        retrieved_contexts = []\n",
    "        for _p in _prompt:\n",
    "            retrieved_contexts.extend(self.retrieve(_p[0]))\n",
    "        \n",
    "        try:\n",
    "            response = self.generate_response(\n",
    "                contexts=retrieved_contexts,\n",
    "                query=original_prompt,\n",
    "                history=history\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "        \n",
    "        return response.text\n",
    "\n",
    "    def stream_complete(\n",
    "        self,\n",
    "        prompts: str,\n",
    "        history: Optional[List[dict]] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> CompletionResponseGen:\n",
    "        \"\"\"\n",
    "        Generate a streamed completion for the given prompt.\n",
    "\n",
    "        :param prompt: The input text prompt.\n",
    "        :param history: Optional history of previous interactions.\n",
    "        :yield: Partial CompletionResponses as text is generated.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            full_response = self.complete(prompts=prompts, history=history)\n",
    "        except Exception as e:\n",
    "            yield CompletionResponse(text=\"\", delta=f\"Error: {e}\")\n",
    "            return\n",
    "\n",
    "        accumulated_text = \"\"\n",
    "        for r in full_response:\n",
    "            accumulated_text += r\n",
    "            yield CompletionResponse(text=accumulated_text, delta=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = Rag(\n",
    "    llm=llm,\n",
    "    transformers=transforms,\n",
    ")\n",
    "    \n",
    "# response = rag.complete(\"Where should I eat in Hanoi?\")\n",
    "# print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import TruCustomApp\n",
    "\n",
    "tru_rag = TruCustomApp(\n",
    "    rag,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=\"simple\",\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
    "    selectors_nocheck=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"What are the tips for solo travelers when exploring a new country for the first time?\",\n",
    "           \"What are the best places to visit in Hanoi?\",\n",
    "           \"What are the best dishes to eat in Hanoi?\"]\n",
    "\n",
    "with tru_rag as recording:\n",
    "    for prompt in prompts:\n",
    "        # prompt = prompts[0]\n",
    "        op = rag.complete(prompt)\n",
    "        print(op)\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_session.get_leaderboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragoon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
