{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.core import Root\n",
    "from snowflake.cortex import Complete\n",
    "from llama_index.core.llms import LLM\n",
    "from typing import Any, List, Dict, Callable, Union, Optional, Tuple\n",
    "from llama_index.core.llms import CompletionResponse, CompletionResponseGen\n",
    "from core.llm.CustomLLM import RagoonBot\n",
    "from core.preprocessing.HYDE.HyDETransform import HyDETransformer\n",
    "from core.preprocessing.MultiStep.MultiStepTransform import MultiStepTransformer\n",
    "from core.preprocessing.rerank.Reranker import Reranker\n",
    "#from geo.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('../../.env')\n",
    "llm = RagoonBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    connection_params = {\n",
    "        \"account\":  os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "        \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "        \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "        \"database\": os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "        \"schema\": os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "        \"warehouse\": os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "        \"service\": os.environ[\"SNOWFLAKE_CORTEX_SEARCH_SERVICE\"],\n",
    "    }\n",
    "except KeyError as e:\n",
    "    print(\"Please set the environment variable: \" + str(e))\n",
    "\n",
    "print(connection_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    snowpark_session = Session.builder.configs(connection_params).create()\n",
    "except Exception as e:\n",
    "    print(\"Error creating Snowpark session: \" + str(e))\n",
    "\n",
    "transforms = {\n",
    "    'HyDE': HyDETransformer(),\n",
    "    'MultiStep': MultiStepTransformer(),\n",
    "    'Rerank': Reranker(\"\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import TruSession\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "\n",
    "from trulens.apps.custom import instrument\n",
    "\n",
    "tru_snowflake_connector = SnowflakeConnector(snowpark_session=snowpark_session)\n",
    "tru_session = TruSession(connector=tru_snowflake_connector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.providers.cortex.provider import Cortex\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens_eval.feedback import GroundTruthAgreement\n",
    "import numpy as np\n",
    "\n",
    "provider = Cortex(snowpark_session, model_engine=\"snowflake-arctic\")\n",
    "\n",
    "f_groundedness = (\n",
    "    Feedback(provider.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "f_context_relevance = (\n",
    "\tFeedback(\n",
    "\t\tprovider.qs_relevance_with_cot_reasons,\n",
    "\t\tname=\"Context Relevance\",\n",
    "\t)\n",
    "\t.on(Select.RecordCalls.retrieve.args.query)\n",
    "\t.on(Select.RecordCalls.retrieve.rets.collect())\n",
    "\t.aggregate(np.mean)\n",
    ")\n",
    "\n",
    "f_answer_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons,\n",
    "    name=\"Answer Relevance\"\n",
    ").on_input_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rag:\n",
    "    def __init__(\n",
    "        self, \n",
    "        llm: LLM = llm,\n",
    "        transformers: Union[str, List[str]] = [\"MultiStep\", \"HyDE\"],\n",
    "        snowpark_session: Session = snowpark_session,\n",
    "        limit_to_retrieve: int = 4,\n",
    "        snowflake_params: Dict[str, str] = connection_params,\n",
    "        search_columns: List[str] = [\"NAME\", \"INFORMATION\"],\n",
    "        retrieve_column: str = \"INFORMATION\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the RAG instance.\n",
    "\n",
    "        TODO: param\n",
    "        \"\"\"\n",
    "        if isinstance(llm, str):\n",
    "            self.llm = RagoonBot(model=llm)\n",
    "        else:\n",
    "            self.llm = llm\n",
    "        \n",
    "        if isinstance(transformers, str):\n",
    "            self.transformers = [transformers]\n",
    "        else:\n",
    "            self.transformers = transformers\n",
    "\n",
    "        self._snowpark_session = snowpark_session\n",
    "        self._limit_to_retrieve = limit_to_retrieve\n",
    "        self.snowflake_params = snowflake_params\n",
    "        self.search_columns = search_columns\n",
    "        self.retrieve_column = retrieve_column\n",
    "\n",
    "    def controller(self, text: str, **kwargs: Any) -> bool:\n",
    "        # If the text is about basic information, return True\n",
    "        prompt = \"\"\"\n",
    "            Return True if the user query is about basic information or general knowledge.\n",
    "            Otherwise, return False.\n",
    "            Do not include any other information, just True or False.\n",
    "\n",
    "            User Query: {}\n",
    "        \"\"\"\n",
    "        response = self.llm.complete(prompt.format(text))\n",
    "        response = response.text\n",
    "        response = response.strip()\n",
    "        #assert response in [\"True\", \"False\"], f\"Invalid response from the controller: {response}\"\n",
    "        return response == \"True\"\n",
    "\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> List[str]:\n",
    "        root = Root(self._snowpark_session)\n",
    "        cortex_search_service = (\n",
    "            root.databases[self.snowflake_params.get(\"database\")]\n",
    "            .schemas[self.snowflake_params.get(\"schema\")]\n",
    "            .cortex_search_services[self.snowflake_params.get(\"service\")]\n",
    "        )\n",
    "        resp = cortex_search_service.search(\n",
    "            query=query,\n",
    "            columns=self.search_columns,\n",
    "            limit=self._limit_to_retrieve,\n",
    "        )\n",
    "\n",
    "        if resp.results:\n",
    "            return [curr[self.retrieve_column] for curr in resp.results]\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "\n",
    "    @instrument\n",
    "    def generate_response(\n",
    "        self,\n",
    "        contexts: List[str] = [],\n",
    "        query: str = None,\n",
    "        history: Optional[List[dict]] = None,\n",
    "        **kwargs: Any\n",
    "    ):\n",
    "        assert query is not None, \"Query cannot be None.\"\n",
    "        if not contexts:\n",
    "            context = \"None\"\n",
    "\n",
    "        context = \"\\n\\n\".join(contexts)\n",
    "        # Combine history with the user prompt\n",
    "        # start with assistant introducing itself\n",
    "        history_text = \"Assistant: Hello, I am Ragoon, an assistant for tourism and travel tasks.\"\n",
    "        if history:\n",
    "            history_text += \"\\n\".join([f\"{entry['role']}: {entry['content']}\" for entry in history])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "            These are the messages between a user and an assistant:\n",
    "            {history_text}\n",
    "            Now, use the following pieces of retrieved context to complete the conversation by answering the user's question. \n",
    "            If you don't know the answer, say that you don't know. \n",
    "            Keep the answer concise.\n",
    "        \"\"\"\n",
    "        prompt += f\"\\n\\nContext: {context} \\n\\nQuery: {query}\"\n",
    "\n",
    "        response = self.llm.complete(prompt)\n",
    "        print(prompt)\n",
    "        return response\n",
    "\n",
    "    @instrument\n",
    "    def complete(\n",
    "        self,\n",
    "        prompts: Union[str, List[str]] = None,\n",
    "        history: Optional[List[dict]] = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Completes the prompt using the RAG model.\n",
    "\n",
    "        :param prompts: str. The prompts to complete.\n",
    "        :return: str. The completed prompts.\n",
    "        \"\"\"\n",
    "        assert prompts is not None, \"Prompt cannot be None.\"\n",
    "        \n",
    "        if isinstance(prompts, str):\n",
    "            _prompt = [[prompts]]\n",
    "            original_prompt = prompts\n",
    "\n",
    "        if isinstance(prompts, list):\n",
    "            _prompt = [prompts]\n",
    "            original_prompt = prompts[0]\n",
    "\n",
    "        # Reduce transforms for basic queries\n",
    "        if self.controller(original_prompt):\n",
    "            # No need for transformers\n",
    "            _prompt = [[original_prompt]]\n",
    "        else:\n",
    "            transforms[\"Rerank\"]._original_string = original_prompt\n",
    "            if self.transformers is not None:\n",
    "                for _transformer in self.transformers:\n",
    "                    prime = transforms.get(_transformer)\n",
    "                    _prompt = prime.transform(_prompt)\n",
    "\n",
    "        retrieved_contexts = []\n",
    "        for _p in _prompt:\n",
    "            retrieved_contexts.extend(self.retrieve(_p[0]))\n",
    "        \n",
    "        try:\n",
    "            response = self.generate_response(\n",
    "                contexts=retrieved_contexts,\n",
    "                query=original_prompt,\n",
    "                history=history\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "        \n",
    "        return response.text\n",
    "\n",
    "    def stream_complete(\n",
    "        self,\n",
    "        prompts: str,\n",
    "        history: Optional[List[dict]] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> CompletionResponseGen:\n",
    "        \"\"\"\n",
    "        Generate a streamed completion for the given prompt.\n",
    "\n",
    "        :param prompt: The input text prompt.\n",
    "        :param history: Optional history of previous interactions.\n",
    "        :yield: Partial CompletionResponses as text is generated.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            full_response = self.complete(prompts=prompts, history=history)\n",
    "        except Exception as e:\n",
    "            yield CompletionResponse(text=\"\", delta=f\"Error: {e}\")\n",
    "            return\n",
    "\n",
    "        accumulated_text = \"\"\n",
    "        for r in full_response:\n",
    "            accumulated_text += r\n",
    "            yield CompletionResponse(text=accumulated_text, delta=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = Rag(\n",
    "        llm=llm\n",
    "    )\n",
    "    \n",
    "# response = rag.complete(\"Where should I eat in Hanoi?\")\n",
    "# print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import TruCustomApp\n",
    "\n",
    "tru_rag = TruCustomApp(\n",
    "    rag,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=\"simple\",\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
    "    selectors_nocheck=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"What are the top travel tips for solo travelers exploring a new country for the first time?\"]\n",
    "\n",
    "with tru_rag as recording:\n",
    "    for prompt in prompts:\n",
    "        rag.complete(prompt)\n",
    "        time.sleep(5)\n",
    "\n",
    "tru_session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if snowpark_session:\n",
    "    # Close the Snowflake session\n",
    "    snowpark_session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowflake2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
